{"title":"分布式日志采集（elk+kafka）","uid":"8da5616698516c85cde26f7cf0077841","slug":"csdn/分布式日志采集（elk+kafka）","date":"2021-03-24T15:15:22.000Z","updated":"2025-02-17T04:22:34.775Z","comments":true,"path":"api/articles/csdn/分布式日志采集（elk+kafka）.json","keywords":"Stephen web3","cover":[],"content":"<link rel=\"stylesheet\" href=\"/owl.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><h2 id=\"目的\"><a href=\"#目的\" class=\"headerlink\" title=\"目的\"></a>目的</h2><p>        分布式系统的日志，每个服务器节点web服务都会产生各自的日志文件，如果想要整合或者排查日志，就需要到每个节点下逐一查看日志文件这样会比较麻烦。所以需要一个方案将日志采集放到一个位置进行存储和查询。 这里就可以使用elk+kafka的方式解决。</p>\n<p>       elk(elasticsearch、logstash、kibana)的首字母缩写。elasticsearch用来存储采集的日志数据，logstash负责采集日志，kibana作为es的可视化分析查询工具。</p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><h3 id=\"eIk-采集日志的原理\"><a href=\"#eIk-采集日志的原理\" class=\"headerlink\" title=\"eIk 采集日志的原理:\"></a>eIk 采集日志的原理:</h3><p>1.需要在每个服务器上安装 logstash</p>\n<p>2.logstash需要配置固定读取某个日志文件</p>\n<p>3.logstash将我们的日志文件格式化为json 的格式输出到es 中</p>\n<p>4.开发者使用kibana连接到es中查询存储日志内容</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/1d56b9dc9d60bc05a6b895c68a2f49d7.png\"></p>\n<h3 id=\"elk-kafka-原理\"><a href=\"#elk-kafka-原理\" class=\"headerlink\" title=\"elk+kafka 原理:\"></a>elk+kafka 原理:</h3><p>1.springboot 项目会基于 aop 的方式拦截系统中日志</p>\n<p>日志(错误日志)<br>错误日志:异常通知</p>\n<p>请求与响应日志信息—前置或者环绕通知。<br>2.将该日志投递到我们 kafka 中注意该过程一定要是异步的形式</p>\n<p>3.Logstash 数据源—kafka 订阅 kafka 的主题获取日志消息内容</p>\n<p>4.在将日志消息内容输出到es 中存放</p>\n<p>5.开发者使用Kibana 连接到 ElasticSeach 查询存储日志内容</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/c938d78318edc4b4fbac8279a8ef9451.png\"></p>\n<h2 id=\"elk-kafka的环境搭建\"><a href=\"#elk-kafka的环境搭建\" class=\"headerlink\" title=\"elk+kafka的环境搭建\"></a>elk+kafka的环境搭建</h2><p>elaticsearch和kibana的安装使用的docker，也可以自己下载安装包进行安装</p>\n<h3 id=\"elaticsearch\"><a href=\"#elaticsearch\" class=\"headerlink\" title=\"elaticsearch\"></a>elaticsearch</h3><p>安装elasticsearch<br>1.下载 ES 镜像问题<br>docker pull elasticsearch<br>2.运行ESdocker run -it --name elasticsearch -d -p 9200:9200 -p 9300:9300 -p  5601:5601 elasticsearch</p>\n<p>3. 测试运行结果<br><a href=\"http://192.168.163.129:9200/\">http://192.168.163.129:9200/</a></p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/ca9693c980772650ca539ec56713f18c.png\"></p>\n<p>如果出现以下报错就是创建的es容器有冲突，需要删除已有的es容器或者镜像重命名</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/fa42ec995d057339d5263e3e4bf720fb.png\"></p>\n<h3 id=\"logstash\"><a href=\"#logstash\" class=\"headerlink\" title=\"logstash\"></a>logstash</h3><p>Logstash 是一个开源数据收集引擎，具有实时管道功能。Logstash 可以动态地将来自不同数据源的数据统一起来，并将数据标准化到你所选择的目的地。</p>\n<p>Logstash 输入数据源:、本地文件、Kafka、Redis、mysql</p>\n<p>Logstash 输出数据源:Es、Mongdb、Redis、Mysql</p>\n<p>安装步骤：</p>\n<p>1.上传 logstash-6.4.3.tar.gz 到服务中</p>\n<p>2.tar -zxvf logstash-6.4.3.tar.gz</p>\n<p>3.cd logstash-6.4.3</p>\n<p>4.bin&#x2F;logstash-plugin install logstash-input-kafka</p>\n<p>5.bin&#x2F;logstash-plugin install logstash-output-elasticsearch</p>\n<p>配置文件mylog.conf：</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/35e99fcf9a7c2223d6eb893d52901ebf.png\"></p>\n<p> 启动：</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/aaa5effc24a01c6086a5a406afde467e.png\"></p>\n<h3 id=\"kibana\"><a href=\"#kibana\" class=\"headerlink\" title=\"kibana\"></a>kibana</h3><p>docker run -it -d -e ELASTICSEARCH URL&#x3D;<a href=\"http://127.0.0.1:9200/\">http://127.0.0.1:9200</a> --name kibana --network&#x3D;container:elasticsearch kibana<br>测试运行结果<br><a href=\"http://192.168.163.129:5601/app/kibana#\">http://192.168.163.129:5601/app/kibana#</a></p>\n<h3 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h3><p>这里我们用window版本的，如果是在Linux环境。可以自行了解安装</p>\n<p>kafka依赖zookeeper，所以需要先装zk:</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/153e0c658f32c87a1689d64e66cfdf66.png\"></p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/2960301ee2ef8cc993808836a56ee83c.png\"></p>\n<p> 演示代码</p>\n<p>演示使用springboot框架，aop前置通知采集请求信息入kafka</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/2130bf342527394ed6fa85f492100c8c.png\"></p>\n<p>kafka的spring-boot配置信息：</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/b6e6a4eac37f07a5a587ecede7602eee.png\"></p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/eed07d2dc96968d29c7a3ea23b5eb3fc.png\"></p>\n<p>  浏览器访问：127.0.0.1:8881&#x2F;项目名称&#x2F;getMeberl,aop前置通知会把请求信息封装投递给kafka，logstash从kafka里自动拿到数据存入到es中，使用kibana查看存储的数据，如图：</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/8e1d3cb051e6569c1346cb943dc4f2ec.png\"></p>\n<p> 复制出来放到格式化工具里</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/96e224420c577d051665ab8b21a0168e.png\"></p>\n<h2 id=\"为什么要使用es存储日志\"><a href=\"#为什么要使用es存储日志\" class=\"headerlink\" title=\"为什么要使用es存储日志\"></a>为什么要使用es存储日志</h2><p>   es是一种搜索服务器，底层是基于_Lucene，支持倒排索引，做搜索的效率是特别高的。基于业务需要还是可以考虑选择_Mongdb、Redis、Mysql。后面会更新一篇flume_采集入hdfs做大数据存储、分析、统计_</p>\n<h2 id=\"为什么elk要结合kafka\"><a href=\"#为什么elk要结合kafka\" class=\"headerlink\" title=\"为什么elk要结合kafka\"></a>为什么elk要结合kafka</h2><p>1.如果单纯的使用 elk 的话，服务器节点扩容 需要每个服务器上安装我们Logstash步骤比较冗余</p>\n<p>2.Logstash 读取本地日志文件，可能会对本地的磁盘 io 性能会有一定影响。</p>\n<h2 id=\"优化\"><a href=\"#优化\" class=\"headerlink\" title=\"优化\"></a>优化</h2><p>        图中可以看出请求触发aop，前置通知中往kafka里send消息，如果kafka出现异常、网络抖动都会影响主流程的一个请求响应效率和是否出异常的问题。所以需要把数据放到内存队列中，然后开一个线程，在另一个线程里循环从内存队列里取数据入kafka这样不会影响请求的正常执行业务和响应。</p>\n<p>Article link： <a href=\"https://tqgoblin.site/post/csdn/%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%EF%BC%88elk+kafka%EF%BC%89/\">https://tqgoblin.site/post/csdn/分布式日志采集（elk+kafka）/</a> <div align=left> Author：<a href=\"https://www.tqgoblin.site\"> Stephen </a> </div></p>\n","text":"目的 分布式系统的日志，每个服务器节点web服务都会产生各自的日志文件，如果想要整合或者排查日志，就需要到每个节点下逐一查看日志文件这样会比较麻烦。所以需要一个...","permalink":"/post/csdn/分布式日志采集（elk+kafka）","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[{"name":"mq","slug":"mq","count":5,"path":"api/categories/mq.json"}],"tags":[{"name":"分布式 elk","slug":"分布式-elk","count":1,"path":"api/tags/分布式-elk.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%9B%AE%E7%9A%84\"><span class=\"toc-text\">目的</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">原理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#eIk-%E9%87%87%E9%9B%86%E6%97%A5%E5%BF%97%E7%9A%84%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">eIk 采集日志的原理:</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#elk-kafka-%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">elk+kafka 原理:</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#elk-kafka%E7%9A%84%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA\"><span class=\"toc-text\">elk+kafka的环境搭建</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#elaticsearch\"><span class=\"toc-text\">elaticsearch</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#logstash\"><span class=\"toc-text\">logstash</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#kibana\"><span class=\"toc-text\">kibana</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#kafka\"><span class=\"toc-text\">kafka</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8es%E5%AD%98%E5%82%A8%E6%97%A5%E5%BF%97\"><span class=\"toc-text\">为什么要使用es存储日志</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88elk%E8%A6%81%E7%BB%93%E5%90%88kafka\"><span class=\"toc-text\">为什么elk要结合kafka</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">优化</span></a></li></ol>","author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"Docker","uid":"a48e6dda0c21e40880cba7e763278b04","slug":"csdn/Docker","date":"2021-03-26T08:52:57.000Z","updated":"2025-02-17T03:37:04.096Z","comments":true,"path":"api/articles/csdn/Docker.json","keywords":"Stephen web3","cover":[],"text":"简介与概述1.Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。 Docker 可以让开发者打包他们的应用以及依赖...","permalink":"/post/csdn/Docker","photos":[],"count_time":{"symbolsCount":"19k","symbolsTime":"17 mins."},"categories":[{"name":"运维","slug":"运维","count":6,"path":"api/categories/运维.json"}],"tags":[{"name":"docker 容器","slug":"docker-容器","count":1,"path":"api/tags/docker-容器.json"}],"author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"MYSQL-性能优化篇","uid":"4e6d25d934b34d1d1306ad13dba25eb2","slug":"csdn/MYSQL-性能优化篇","date":"2021-03-20T13:00:38.000Z","updated":"2025-02-17T04:22:34.789Z","comments":true,"path":"api/articles/csdn/MYSQL-性能优化篇.json","keywords":"Stephen web3","cover":[],"text":"为什么要进行数据库优化？1.避免网站页面出现访问错误 由于数据库连接timeout产生页面5xx错误 由于慢查询造成页面无法加载 由于阻塞造成数据无法提交 2....","permalink":"/post/csdn/MYSQL-性能优化篇","photos":[],"count_time":{"symbolsCount":"23k","symbolsTime":"21 mins."},"categories":[{"name":"数据库","slug":"数据库","count":2,"path":"api/categories/数据库.json"}],"tags":[{"name":"数据库 mysql","slug":"数据库-mysql","count":1,"path":"api/tags/数据库-mysql.json"}],"author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}