{"title":"SparkSQL详解","uid":"2350649905fde260e7257127a691caec","slug":"csdn/SparkSQL详解","date":"2023-02-06T09:00:19.000Z","updated":"2025-02-17T01:58:21.584Z","comments":true,"path":"api/articles/csdn/SparkSQL详解.json","keywords":"Stephen web3","cover":[],"content":"<link rel=\"stylesheet\" href=\"/owl.css\"><link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><script class=\"meting-secondary-script-marker\" src=\"/assets/js/Meting.min.js\"></script><span id=\"more\"></span>\n\n<p><strong>目录</strong></p>\n<p><a href=\"#SparkSQL%E6%A6%82%E8%BF%B0\">SparkSQL概述</a></p>\n<p><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFSpark%20SQL\">什么是Spark SQL</a></p>\n<p><a href=\"#Spark%20SQL%E7%89%B9%E7%82%B9\">Spark SQL特点</a></p>\n<p><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFDataFrame\">什么是DataFrame</a></p>\n<p><a href=\"#RDD%E4%B8%8EDataFrame%E5%8C%BA%E5%88%AB%EF%BC%9A\">RDD与DataFrame区别：</a></p>\n<p><a href=\"#%E4%BB%80%E4%B9%88%E6%98%AFDataSet\">什么是DataSet</a></p>\n<p><a href=\"#SparkSQL%E7%BC%96%E7%A8%8B\">SparkSQL编程</a></p>\n<p><a href=\"#%E6%96%B0%E7%9A%84%E8%B5%B7%E5%A7%8B%E7%82%B9\">新的起始点</a></p>\n<p><a href=\"#DataFrame\">DataFrame</a></p>\n<p><a href=\"#%E5%88%9B%E5%BB%BA\">创建</a></p>\n<p><a href=\"#SQL%E8%AF%AD%E6%B3%95\">SQL语法</a></p>\n<p><a href=\"#DSL%E8%AF%AD%E6%B3%95\">DSL语法</a></p>\n<p><a href=\"#RDD%E8%BD%AC%E6%8D%A2%E4%B8%BADataFrame&DataFrame%E8%BD%AC%E6%8D%A2%E4%B8%BARDD\">RDD转换为DataFrame&amp;DataFrame转换为RDD</a></p>\n<p><a href=\"#DataSet\">DataSet</a></p>\n<p><a href=\"#%E5%88%9B%E5%BB%BADataSet\">创建DataSet</a></p>\n<p><a href=\"#DataFrame%E8%BD%ACDataSet&DataSet%E8%BD%ACDataFrame\">DataFrame转DataSet&amp;DataSet转DataFrame</a></p>\n<p><a href=\"#RDD%E8%BD%ACDataSet&DataSet%E8%BD%ACRDD\">RDD转DataSet&amp;DataSet转RDD</a></p>\n<p><a href=\"#RDD%E3%80%81DataFrame%E3%80%81DataSet%E4%B8%89%E8%80%85%E7%9A%84%E5%85%B3%E7%B3%BB\">RDD、DataFrame、DataSet三者的关系</a></p>\n<p><a href=\"#%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB%EF%BC%9A\">版本区别</a></p>\n<p><a href=\"#%E4%B8%89%E8%80%85%E7%9A%84%E5%85%B1%E6%80%A7\">三者的共性</a></p>\n<p><a href=\"#%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB\">三者的区别</a></p>\n<p><a href=\"#IDEA%E5%88%9B%E5%BB%BASparkSQL%E7%A8%8B%E5%BA%8F\">IDEA创建SparkSQL程序</a></p>\n<p><a href=\"#%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0\">用户自定义函数</a></p>\n<p><a href=\"#1%E3%80%81%E5%88%9B%E5%BB%BADataFrame\">1、创建DataFrame</a></p>\n<p><a href=\"#2%E3%80%81%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0(%E5%BC%B1%E7%B1%BB%E5%9E%8B)\">2、用户自定义聚合函数(弱类型)</a></p>\n<p><a href=\"#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98\">数据的加载和保存</a></p>\n<p><a href=\"#%E9%80%9A%E7%94%A8%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98%E6%96%B9%E5%BC%8F\">通用的加载和保存方式</a></p>\n<p><a href=\"#parquet\">parquet</a></p>\n<p><a href=\"#JSON\">JSON</a></p>\n<p><a href=\"#CSV\">CSV</a></p>\n<p><a href=\"#MySQL\">MySQL</a></p>\n<p><a href=\"#Hive\">Hive</a></p>\n<p><a href=\"#SparkSQL%E4%BB%A3%E7%A0%81%E6%A0%B7%E4%BE%8B\">SparkSQL代码样例</a></p>\n<hr>\n<h2 id=\"SparkSQL-概述\"><a href=\"#SparkSQL-概述\" class=\"headerlink\" title=\"SparkSQL****概述\"></a><strong>SparkSQL****概述</strong></h2><h3 id=\"什么是-Spark-SQL\"><a href=\"#什么是-Spark-SQL\" class=\"headerlink\" title=\"什么是****Spark SQL\"></a><strong>什么是****Spark SQL</strong></h3><p>Spark SQL是 Spark 用来处理结构化数据的一个模块，它提供了 2 个编程抽象：DataFrame 和</p>\n<p>DataSet，并且作为分布式 SQL 查询引擎的作用。</p>\n<h3 id=\"Spark-SQL-特点\"><a href=\"#Spark-SQL-特点\" class=\"headerlink\" title=\"Spark SQL****特点\"></a><strong>Spark SQL****特点</strong></h3><p>(1)、易整合</p>\n<p>将SQL查询与Spark程序无缝混合</p>\n<p>(2)、统一的数据访问方式</p>\n<p>以相同的方式连接到任何数据源</p>\n<p>(3)、兼容 Hive</p>\n<p>在现有仓库上运行SQL或HiveQL查询</p>\n<p>(4)、 标准的数据连接</p>\n<p>通过JDBC或ODBC连接</p>\n<h3 id=\"什么是-DataFrame\"><a href=\"#什么是-DataFrame\" class=\"headerlink\" title=\"什么是****DataFrame\"></a><strong>什么是****DataFrame</strong></h3><p>与 RDD 类似，DataFrame 也是一个分布式数据容器。然而 DataFrame 更像传统数据库的二维表</p>\n<p>格，除了数据以外，还记录数据的结构信息，即 schema。同时，与 Hive 类似，DataFrame 也支</p>\n<p>持嵌套数据类型（struct、array 和 map）。从 API 易用性的角度上看，DataFrame API 提供的是</p>\n<p>一套高层的关系操作，比函数式的 RDD API 要更加友好，门槛更低。</p>\n<h4 id=\"RDD与DataFrame-区别：\"><a href=\"#RDD与DataFrame-区别：\" class=\"headerlink\" title=\"RDD与DataFrame****区别：\"></a><strong>RDD<strong><strong>与</strong></strong>DataFrame****区别：</strong></h4><p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/eba3f98b18ebc6c6a94c80790e97664a.png\"></p>\n<p><strong>例子：</strong></p>\n<p>users . join ( events , users ( “id” ) =&#x3D;&#x3D; events ( “uid” )). filter ( events ( “date” ) &gt; “2022- 01-01” )</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/5f7905a856fff8027e3474df272a2a99.png\"></p>\n<h3 id=\"什么是-DataSet\"><a href=\"#什么是-DataSet\" class=\"headerlink\" title=\"什么是****DataSet\"></a><strong>什么是****DataSet</strong></h3><p>DataSet是分布式数据集合。DataSet是Spark1.6中添加的一个新抽象，是DataFrame的一个扩</p>\n<p>展。它提供了RDD的优势（强类型，使用强大的lambda函数的能力）以及SparkSQL优化执行引</p>\n<p>擎的优点。DataSet也可以使用功能性的转换（操作map，flatMap，filter等等）。</p>\n<p>(1)、是Dataframe API 的一个扩展，是 Spark 最新的数据抽象。</p>\n<p>(2)、用户友好的API 风格，既具有类型安全检查也具有 Dataframe 的查询优化特性。</p>\n<p>(3)、Dataset 支持编解码器，当需要访问非堆上的数据时可以避免反序列化整个对象，提高了效</p>\n<p>率。</p>\n<p>(4)、样例类被用来在 Dataset 中定义数据的结构信息，样例类中每个属性的名称直接映射到</p>\n<p>DataSet 中的字段名称。</p>\n<p>(5)、Dataframe 是Dataset 的特列，DataFrame&#x3D;Dataset[Row] ，所以可以通过 as 方法将</p>\n<p>Dataframe转换为 Dataset。Row 是一个类型,跟 Car、Person 这些的类型一样，所有的表结构信</p>\n<p>息我都用 Row 来表示。(6)、DataSet 是强类型的。比如可以有 Dataset[Car]，Dataset[Person]。</p>\n<p>(7)、DataFrame 只是知道字段，但是不知道字段的类型，所以在执行这些操作的时候是没办法在</p>\n<p>编译的时候检查是否类型失败的，比如你可以对一个 String 进行减法操作，在执行的时候才报</p>\n<p>错，而 DataSet 不仅仅知道字段，而且知道字段类型，所以有更严格的错误检查。就跟 JSON 对</p>\n<p>象和类对象之间的类比。</p>\n<h2 id=\"SparkSQL-编程\"><a href=\"#SparkSQL-编程\" class=\"headerlink\" title=\"SparkSQL****编程\"></a><strong>SparkSQL****编程</strong></h2><h3 id=\"新的起始点\"><a href=\"#新的起始点\" class=\"headerlink\" title=\"新的起始点\"></a><strong>新的起始点</strong></h3><p>在老的版本中，SparkSQL 提供两种 SQL 查询起始点：一个叫 SQLContext，用于 Spark 自己提</p>\n<p>供的 SQL 查询；一个HiveContext，用于连接Hive 的查询。</p>\n<p>SparkSession 是 Spark 最新的 SQL 查询起始点，实质上是 SQLContext 和 HiveContext 的组</p>\n<p>合，所以在 SQLContext 和HiveContext 上可用的 API 在 SparkSession 上同样是可以使用的。</p>\n<p>SparkSession 内部封装了 sparkContext，所以计算实际上是由 sparkContext 完成的。</p>\n<h3 id=\"DataFrame\"><a href=\"#DataFrame\" class=\"headerlink\" title=\"DataFrame\"></a><strong>DataFrame</strong></h3><p>SparkSQL的DataFrame API允许我们使用DataFrame而不用必须去注册临时表或者生产SQL</p>\n<p>表达式。DataFrame API既有transformation操作也有action操作。</p>\n<h4 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a><strong>创建</strong></h4><p>在 Spark SQL 中 SparkSession 是创建DataFrame 和执行 SQL 的入口，创建</p>\n<p>DataFrame 有三种方式：</p>\n<p>(1)、通过 Spark 的数据源进行创建；</p>\n<p>(2)、从一个存在的 RDD 进行转换；</p>\n<p>(3)、还可以从 Hive Table 进行查询返回。</p>\n<p>从 Spark 数据源进行创建</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F;1 、查看 Spark 数据源进行创建的文件格式</p>\n<p>&#x2F;&#x2F;spark.read.</p>\n<p>&#x2F;&#x2F;2 、读取 json 文件创建 DataFrame</p>\n<p>&#x2F;&#x2F; 创建一个 user.json 文件</p>\n<p>val df &#x3D; spark.read.json(“&#x2F;usr&#x2F;local&#x2F;soft&#x2F;data&#x2F;user.json”)</p>\n<p>&#x2F;&#x2F;3 、展示结果</p>\n<p>df.show</p>\n<p>df.createTempView(“user”)</p>\n<p>spark.sql(“select * from user”).show</p></blockquote>\n<p>注意：如果从内存中获取数据，Spark可以知道数据类型具体是什么。如果是数字，默</p>\n<p>认作为Int处理；但是从文件中读取的数字，不能确定是什么类型，索引用bigint接收，</p>\n<p>可以和Long类型转换，但是和Int不能进行转换。</p>\n<ul>\n<li>从一个存在的 RDD 进行转换（后面讲解）</li>\n<li>还可以从 Hive Table 进行查询返回（后面讲解）</li>\n</ul>\n<h4 id=\"SQL-语法\"><a href=\"#SQL-语法\" class=\"headerlink\" title=\"SQL****语法\"></a><strong>SQL****语法</strong></h4><p>SQL语法风格是指我们查询数据的时候使用SQL语句来查询，这种风格的查询必须要有</p>\n<p>临时视图或者全局视图来辅助。</p>\n<p>(1)、读取JSON文件创建DataFrame</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val df &#x3D; spark.read.json(“&#x2F;usr&#x2F;local&#x2F;soft&#x2F;data&#x2F;user.json”)</p></blockquote>\n<p>(2)、对DataFrame创建一个临时表</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.createOrReplaceTempView(“people”)</p></blockquote>\n<p>注意：View和table的区别，View是不能修改的，只能查，而table可以增删改查。</p>\n<p>(3)、通过SQL语句实现查询全表</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>spark.sql(“select * from people”).show</p></blockquote>\n<p>(4)、结果展示</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.show</p></blockquote>\n<p>注意：普通临时表是Session范围内的，如果想应用范围内有效，可以使用全局临时</p>\n<p>表。使用全局临时表时需要全路径访问，如：global_temp.people</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>spark.newSession.sql(“select * from people”).show 报错</p></blockquote>\n<p>(5) 、对于 DataFrame 创建一个全局表</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.createOrReplaceGlobalTempView(“people”)</p>\n<p>df.createGlobalTempView(“people”)</p>\n<p>spark.newSession.sql(“select * from global_temp.people”).show</p></blockquote>\n<h4 id=\"DSL-语法\"><a href=\"#DSL-语法\" class=\"headerlink\" title=\"DSL****语法\"></a><strong>DSL****语法</strong></h4><p>DataFrame提供一个特定领域语言（DSL）去管理结构化的数据。可以在Scala、Java、</p>\n<p>Python和R中使用DSL，使用DSL语法风格不必去创建临时视图了。</p>\n<p>(1)、创建一个DataFrame</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val df &#x3D; spark.read.json(“&#x2F;usr&#x2F;local&#x2F;soft&#x2F;data&#x2F;user.json”)</p></blockquote>\n<p>(2)、查看DataFrame 的 Schema 信息</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.printSchem</p></blockquote>\n<p>(3)、只查看“age”列数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F;df. &#x2F;&#x2F;tab 键查看 df 中的方法</p>\n<p>df.select(“age”).show()</p></blockquote>\n<p>(4)、查看”username”列数据以及”age+1”数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.select(“age” + 1).show() &#x2F;&#x2F; 报错</p>\n<p>df.select($“age” + 1).show()</p>\n<p>df.select(‘age + 1).show()</p>\n<p>df.select($“username”,$“age” + 1).show()</p>\n<p>df.select($“username”,$“age” + 1 as “newage”).show() &#x2F;&#x2F; 取别名</p></blockquote>\n<p>注意：涉及到运算的时候，每列都必须使用$，或者采用引号表达式：单引号+字段名</p>\n<p>(5)、查看“age”大于“30”的数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.filter($“age” &gt; 20).show()</p>\n<p>df.filter($“age” &gt; 30).show()</p></blockquote>\n<p>(6)、按照“age”分组，查看数据条数</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.groupBy(“age”).count.show()</p></blockquote>\n<h4 id=\"RDD转换为DataFrame-DataFrame转换为RDD\"><a href=\"#RDD转换为DataFrame-DataFrame转换为RDD\" class=\"headerlink\" title=\"RDD转换为DataFrame&amp;DataFrame转换为RDD\"></a><strong>RDD<strong><strong>转换为</strong></strong>DataFrame&amp;DataFrame<strong><strong>转换为</strong></strong>RDD</strong></h4><p>在IDE中开发时，如果需要 RDD 与DF 或者 DS 之间操作，那么都需要引入 import</p>\n<p>spark.implicits._</p>\n<p>这里的spark不是scala中的包名，而是创建的sparkSession对象中的变量名称，所以必</p>\n<p>须先创建SparkSession对象再导入。这里的spark对象不能使用var声明，因为Scala只</p>\n<p>支持val修饰的对象的引入。</p>\n<p>注意：spark-shell中无需导入，自动完成此操作。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val rdd &#x3D; sc.makeRDD(List(1,2,3,4))</p>\n<p>&#x2F;&#x2F;rdd. &#x2F;&#x2F;tab 键查看 rdd 所有的方法</p>\n<p>val df &#x3D; rdd.toDF(“id”)</p>\n<p>df.show()</p>\n<p>&#x2F;&#x2F;df. &#x2F;&#x2F;tab 键查看 df 所有的方法</p>\n<p>df.rdd</p></blockquote>\n<h3 id=\"DataSet\"><a href=\"#DataSet\" class=\"headerlink\" title=\"DataSet\"></a><strong>DataSet</strong></h3><p>DataSet是具有<strong>强类型</strong>的数据集合，需要提供对应的类型信息。</p>\n<h4 id=\"创建-DataSet\"><a href=\"#创建-DataSet\" class=\"headerlink\" title=\"创建****DataSet\"></a><strong>创建****DataSet</strong></h4><p>(1)、使用样例类序列创建DataSet</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F;case class Perso(name:String,age:Long)</p>\n<p>val list &#x3D; List(Perso(“zhangsan”,30),Person(“lisi”,20))</p>\n<p>val ds &#x3D; list.toDS</p>\n<p>ds.show</p></blockquote>\n<h4 id=\"DataFrame转DataSet-DataSet转DataFrame\"><a href=\"#DataFrame转DataSet-DataSet转DataFrame\" class=\"headerlink\" title=\"DataFrame转DataSet&amp;DataSet转DataFrame\"></a><strong>DataFrame<strong><strong>转</strong></strong>DataSet&amp;DataSet<strong><strong>转</strong></strong>DataFrame</strong></h4><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F;df &#x2F;&#x2F; 查看是否存在 df</p>\n<p>&#x2F;&#x2F;case class Emp(age:Long,username:String)</p>\n<p>&#x2F;&#x2F;val ds &#x3D; df.as[Emp]</p>\n<p>&#x2F;&#x2F;ds.show()</p>\n<p>&#x2F;&#x2F;ds. &#x2F;&#x2F;tab 键查看方法</p>\n<p>&#x2F;&#x2F;ds.toDF</p></blockquote>\n<h4 id=\"RDD转DataSet-DataSet转RDD\"><a href=\"#RDD转DataSet-DataSet转RDD\" class=\"headerlink\" title=\"RDD转DataSet&amp;DataSet转RDD\"></a><strong>RDD<strong><strong>转</strong></strong>DataSet&amp;DataSet<strong><strong>转</strong></strong>RDD</strong></h4><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val rdd &#x3D; sc.makeRDD(List(Emp(30,”zhangsan”),Emp(20,”lisi”)))</p>\n<p>rdd.toDS</p>\n<p>&#x2F;&#x2F; 前提条件：必须是样例类把类型准备好</p>\n<p>val rdd &#x3D; sc.makeRDD(List(1,2,3,4))</p>\n<p>rdd.toDS</p>\n<p>val rdd &#x3D; sc.makeRDD(List(Emp(30,”zhangsan”),Emp(20,”lisi”)))</p>\n<p>val ds &#x3D; rdd.toDS</p>\n<p>val rdd1 &#x3D; ds.rdd</p></blockquote>\n<h3 id=\"RDD、DataFrame、DataSet-三者的关系\"><a href=\"#RDD、DataFrame、DataSet-三者的关系\" class=\"headerlink\" title=\"RDD、DataFrame、DataSet****三者的关系\"></a><strong>RDD<strong><strong>、</strong></strong>DataFrame<strong><strong>、</strong></strong>DataSet****三者的关系</strong></h3><p>在SarpkSQL中Spark为我们提供了两个新的抽象，分别是DataFrame和DataSet。</p>\n<h4 id=\"版本区别\"><a href=\"#版本区别\" class=\"headerlink\" title=\"版本区别\"></a><strong>版本区别</strong></h4><p>版本来看：</p>\n<p>Spark1.0 —-&gt;RDD</p>\n<p>Spark1.3 —-&gt;DataFrame</p>\n<p>Spark1.6 —-&gt;DataSet</p>\n<p>如果同样的数据都给到这三个数据结构，他们分别计算后，都会给出相同的结果。不同的是</p>\n<p>他们的执行效率和执行方式。在后期的Spark版本中，DataSet有可能会逐步取代RDD和</p>\n<p>DataFrame成为唯一的API接口。</p>\n<h4 id=\"三者的共性\"><a href=\"#三者的共性\" class=\"headerlink\" title=\"三者的共性\"></a><strong>三者的共性</strong></h4><p>1、RDD、DataFrame、Dataset 全都是spark平台下的分布式弹性数据集，为处理超大型数</p>\n<p>据提供便利。</p>\n<p>2、三者都有惰性机制，在进行创建、转换，如map方法时，不会立即执行，只有在遇到</p>\n<p>Action如foreach时，三者才会开始遍历运算。</p>\n<p>3、三者都会根据spark的内存情况自动缓存运算，这样即使数据量很大，也不用担心会内存</p>\n<p>溢出。</p>\n<p>4、三者都有partition的概念。</p>\n<p>5、三者有许多共同的函数，如filter，排序等。</p>\n<p>6、在对DataFrame和Dataset进行操作许多操作都需要这个包进行支持：import</p>\n<p>spark.implicits._。</p>\n<p>7、DataFrame和Dataset均可使用模式匹配获取各个字段的值和类型。</p>\n<h4 id=\"三者的区别\"><a href=\"#三者的区别\" class=\"headerlink\" title=\"三者的区别\"></a><strong>三者的区别</strong></h4><p>1.RDD:</p>\n<p>(1)、RDD 一般和 spark mlib 同时使用</p>\n<p>(2)、RDD 不支持 sparksql 操作</p>\n<p>2.DataFrame:</p>\n<p>(1)、与 RDD 和 Dataset 不同，DataFrame 每一行的类型固定为 Row，每一列的值没法直接</p>\n<p>访问，只有通过解析才能获取各个字段的值。</p>\n<p>(2)、DataFrame 与 Dataset 一般不与 spark mlib 同时使用。</p>\n<p>(3)、DataFrame 与 Dataset 均支持 sparksql 的操作，比如 select，groupby 之类，还能注</p>\n<p>册临时表&#x2F;视窗，进行 sql 语句操作。</p>\n<p>(4)、DataFrame 与 Dataset 支持一些特别方便的保存方式，比如保存成 csv，可以带上表</p>\n<p>头，这样每一列的字段名一目了然。</p>\n<p>3.Dataset:</p>\n<p>(1)、Dataset 和DataFrame 拥有完全相同的成员函数，区别只是每一行的数据类型不同。</p>\n<p>(2)、DataFrame 也可以叫 Dataset[Row],每一行的类型是 Row，不解析，每一行究竟有哪些</p>\n<p>字段，各个字段又是什么类型都无从得知，只能用上面提到的 getAS 方法或者共性中的第七</p>\n<p>条提到的模式匹配拿出特定字段。而 Dataset 中，每一行是什么类型是不一定的，在自定义</p>\n<p>了 case class 之后可以很自由的获得每一行的信息。</p>\n<h3 id=\"IDEA创建SparkSQL程序\"><a href=\"#IDEA创建SparkSQL程序\" class=\"headerlink\" title=\"IDEA创建SparkSQL程序\"></a><strong>IDEA创建SparkSQL程序</strong></h3><p>实际开发中，都是使用IDEA中进行开发的。IDEA 中程序的打包和运行方式都和 SparkCore</p>\n<p>类似，Maven 依赖中需要添加新的依赖项：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&lt;!– <a href=\"https://mvnrepository.com/artifact/org.apache.spark/spark-sql\">https://mvnrepository.com/artifact/org.apache.spark/spark-sql</a> –&gt;</p>\n<p>&lt;dependency&gt;</p>\n<p>&lt;groupId&gt; org.apache.spark &lt;&#x2F;groupId&gt;</p>\n<p>&lt;artifactId&gt; spark-sql_2.12 &lt;&#x2F;artifactId&gt;</p>\n<p>&lt;version&gt; 2.4.5 &lt;&#x2F;version&gt;</p>\n<p>&lt;&#x2F;dependency&gt;</p></blockquote>\n<div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">rdd</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">RDD</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo01_SparkSql</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// new SparkSession() //表示没有构造器在这可以访问</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//原因：构造方法私有化，所以在外面不能直接访问</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//builder()构建器构建对象,使用getOrCreate()构建，获取或创建//注意：创建环境的时候需要告知连的是什么,通过config()将配置对象传进去</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//在使用DataFrame时，如果设计到转换操作，需要引入转换规则</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">implicits</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataFrame</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// val df: DataFrame = spark</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .read</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .json(&quot;data/user.json&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataFrame =&gt;SQL</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.createOrReplaceTempView(&quot;user&quot;)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// &quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |select * from user</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |&quot;&quot;&quot;.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// &quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |select age from user</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |&quot;&quot;&quot;.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// &quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |select avg(age) from user</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |&quot;&quot;&quot;.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataFrame =&gt;DSL</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//在使用DataFrame时，如果设计到转换操作，需要引入转换规则</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// import spark.implicits._</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.select(&quot;age&quot;,&quot;username&quot;).show</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.select($&quot;age&quot;+ 1 ).show</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.select(&#39;age + 1).show</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO DataSet</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataFrame其实就是特定泛型到DataSet</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// val seq: Seq[Int] = Seq(1, 2, 3, 4)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// val ds: Dataset[Int] = seq.toDS()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// ds.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//RDD &lt;=&gt; DataFrame</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> rdd</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">RDD</span><span style=\"color: #BABED8\">[(</span><span style=\"color: #FFCB6B\">Int</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Int</span><span style=\"color: #BABED8\">)] </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sparkContext.makeRDD(</span><span style=\"color: #FFCB6B\">List</span><span style=\"color: #BABED8\">((</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">zhangsan</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">20</span><span style=\"color: #BABED8\">),(</span><span style=\"color: #F78C6C\">2</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">lisi</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">21</span><span style=\"color: #BABED8\">),</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">wangwu</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">23</span><span style=\"color: #BABED8\">)))</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> rdd.toDF(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">id</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">name</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">age</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df.show()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> rdd1</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">RDD</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> df.rddrdd1.foreach(println)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataFrame &lt;=&gt; DataSet</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> ds</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> df.as[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">]</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">ds.show()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df1</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> ds.toDF(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">id</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">name</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">age</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df1.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//RDD &lt;=&gt; DataSet</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//DataSet:有数据有类型有结构</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> ds2</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> rdd.map </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF; font-style: italic\">case</span><span style=\"color: #BABED8\"> (id, name, age) </span><span style=\"color: #89DDFF\">=&gt;</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">(id, name, age)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span><span style=\"color: #BABED8\">.toDS()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">ds2.show()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> rdd2</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">RDD</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> ds2.rdd</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">rdd2.foreach(println)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">case</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\"> (id</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Int</span><span style=\"color: #BABED8\">,name</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">,age</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Int</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><h3 id=\"用户自定义函数\"><a href=\"#用户自定义函数\" class=\"headerlink\" title=\"用户自定义函数\"></a><strong>用户自定义函数</strong></h3><p>用户可以通过spark.udf功能添加自定义函数，实现自定义功能。</p>\n<p>UDF</p>\n<h4 id=\"1、创建DataFrame\"><a href=\"#1、创建DataFrame\" class=\"headerlink\" title=\"1、创建DataFrame\"></a>1、<strong>创建DataFrame</strong></h4><div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">rdd</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">RDD</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo02_SparkSql_UDF</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">implicits</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> spark.read.json(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">data/user.json</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df.createOrReplaceTempView(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">user</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span><span style=\"color: #676E95; font-style: italic\">// spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// &quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |select age,&quot;name&quot; + username from user</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// |&quot;&quot;&quot;.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// .show()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.udf.register(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">prefixName</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,(name</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">=&gt;&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">name:</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> name</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|select age,prefixName(username) from user</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><p>强类型的DataSet和弱类型的DataFrame都提供了相关的聚合函数，如count()，</p>\n<p>countDistinct(),avg(),max(),min()。除此之外，用户可以设定自己的自定义聚合函数。通过继</p>\n<p>承UserDefinedAggregateFunction来实现用户自定义弱类型聚合函数。从Spark3.0版本后</p>\n<p>UserDefinedAggregateFunction已经不推荐使用了，可以统一采用强类型聚合函数</p>\n<p>Aggregator。</p>\n<h4 id=\"2、用户自定义聚合函数-弱类型\"><a href=\"#2、用户自定义聚合函数-弱类型\" class=\"headerlink\" title=\"2、用户自定义聚合函数(弱类型)\"></a>2、<strong>用户自定义聚合函数(弱类型)</strong></h4><div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">expressions</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">MutableAggregationBuffer</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">UserDefinedAggregateFunction</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">types</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataType</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">StructField</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo03_SparkSql_UDAF</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> spark.read.json(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">data/user.json</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df.createOrReplaceTempView(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">user</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.udf.register(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">ageAvg</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|select ageAvg(age) from user</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">/**</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 自定义聚合函数类：计算年龄的平均值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 1、继承UserDefinedAggregateFunction</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 2、重写方法(8)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*/</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">extends</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">UserDefinedAggregateFunction</span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//输入数据的结构 IN</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">inputSchema</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\">(</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">(</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructField</span><span style=\"color: #BABED8\">(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">age</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区的结构 Buffer</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">bufferSchema</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\">(</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">(</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//所有年龄的和</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructField</span><span style=\"color: #BABED8\">(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">total</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #BABED8\">) ,</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//所有年龄出现的次数</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructField</span><span style=\"color: #BABED8\">(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">count</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//函数计算结果的数据类型：Out</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">dataType</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataType</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #676E95; font-style: italic\">//函数的稳定性</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">deterministic</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Boolean</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">true</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区初始化</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">initialize</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buffer</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">MutableAggregationBuffer</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer.update(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer.update(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//根据输入的值更新缓冲区数据</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">update</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buffer</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">MutableAggregationBuffer</span><span style=\"color: #BABED8\">, </span><span style=\"color: #BABED8; font-style: italic\">input</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//buffer.getLong(0)缓冲区之前的值 + input.getLong(0)输入的值</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer.update(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">,buffer.getLong(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> input.getLong(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer.update(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">,buffer.getLong(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区数据合并</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">merge</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buffer1</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">MutableAggregationBuffer</span><span style=\"color: #BABED8\">, </span><span style=\"color: #BABED8; font-style: italic\">buffer2</span><span style=\"color: #BABED8\">:</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x y</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//1 2 3 4</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x+y===&gt;x</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x y</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//3 3 4</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x+y===&gt;x</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x y</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//6 4</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//x+y===&gt;x</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer1.update(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">,buffer1.getLong(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buffer2.getLong(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer1.update(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">,buffer1.getLong(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buffer2.getLong(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">))</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//计算平均值</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">evaluate</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buffer</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Any</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buffer.getLong(</span><span style=\"color: #F78C6C\">0</span><span style=\"color: #BABED8\">) </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> buffer.getLong(</span><span style=\"color: #F78C6C\">1</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">（用户自定义聚合函数（</span><span style=\"color: #FFCB6B\">Spark3</span><span style=\"color: #F78C6C\">.0</span><span style=\"color: #BABED8\">.0以下版本的强类型）</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">expressions</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">Aggregator</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">MutableAggregationBuffer</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">UserDefinedAggregateFunction</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">types</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataType</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">LongType</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">StructField</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">StructType</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Row</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">TypedColumn</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo03_SparkSql_UDAF2</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">implicits</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> spark.read.json(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">data/user.json</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//在Spark3.0.0以下的版本，也就是我们所用的版本是不能在sql中使用强类型UDAF操作</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//SQL &amp; DSL</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//Spark3.0.0以下的版本，强类型UDAF聚合函数使用DSL语法操作</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> ds</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Dataset</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> df.as[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">]</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//将UDAF函数转为查询的列对象</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> udaf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">TypedColumn</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\">().toColumn</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//查询</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">ds.select(udaf).show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">/**</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 自定义聚合函数类：计算年龄的平均值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 1、继承UserDefinedAggregateFunction</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 2、重写方法(8)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*/</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">case</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">(username</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">,age</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">BigInt</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">/**</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 自定义聚合函数类：计算年龄的平均值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 1、继承 org.apache.spark.sql.expressions.Aggregator,定义泛型</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* IN：输入的数据类型 User</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* BUF：缓冲区的数据类型</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* OUT：输出的数据类型 Long</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 2、重写方法(6)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*/</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">case</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">(</span><span style=\"color: #89DDFF\">var</span><span style=\"color: #BABED8\"> total</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">var</span><span style=\"color: #BABED8\"> count</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">extends</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Aggregator</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">User</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">]</span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// z &amp; zero都为初始值或零值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区的初始化</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">zero</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">(</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//根据输入的数据更新缓冲区数据override def reduce(buff: Buff, in: User): Buff = &#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.total </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff.total </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> in.age.toInt</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.count </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff.count </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">1</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//合并缓冲区</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">merge</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buff1</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">, </span><span style=\"color: #BABED8; font-style: italic\">buff2</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1.total </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff1.total </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buff2.total</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1.count </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff1.count </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buff2.count</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//计算结果</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">finish</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buff</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.total </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> buff.count</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区的编码操作</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">bufferEncoder</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">.product</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//输出的编码操作</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">outputEncoder</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">.scalaLong</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><p>用户自定义聚合函数（spark3.0.0以上版本的强类型）</p>\n<p><strong>注意：</strong> <strong>spark3.0.0</strong> <strong>一下没有</strong> <strong>functions.udaf</strong> <strong>，想要使用需要去修改</strong> <strong>pom</strong> <strong>文件中</strong> <strong>spark</strong> <strong>版本。</strong></p>\n<div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">expressions</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">Aggregator</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">,</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">functions</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo04_SparkSql_UDAF1</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">implicits</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> spark.read.json(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">data/user.json</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df.createOrReplaceTempView(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">user</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)spark.udf.register(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">ageAvg</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, functions.udaf(</span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\">))</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|select ageAvg(age) from user</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">/**</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 自定义聚合函数类：计算年龄的平均值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 1、继承 org.apache.spark.sql.expressions.Aggregator,定义泛型</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* IN：输入的数据类型 Long</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* BUF：缓冲区的数据类型</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* OUT：输出的数据类型 Long</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">* 2、重写方法(6)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">*/</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">case</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">(</span><span style=\"color: #89DDFF\">var</span><span style=\"color: #BABED8\"> total</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">var</span><span style=\"color: #BABED8\"> count</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">class</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">MyAvgUDAF</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">extends</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Aggregator</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">,</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">]</span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// z &amp; zero都为初始值或零值</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区的初始化</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">zero</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">(</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">,</span><span style=\"color: #F78C6C\">0L</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//根据输入的数据更新缓冲区数据</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">reduce</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buff</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">, </span><span style=\"color: #BABED8; font-style: italic\">in</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.total </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff.total </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> in</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.count </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff.count </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> </span><span style=\"color: #F78C6C\">1</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//合并缓冲区</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">merge</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buff1</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">, </span><span style=\"color: #BABED8; font-style: italic\">buff2</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1.total </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff1.total </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buff2.total</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1.count </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> buff1.count </span><span style=\"color: #89DDFF\">+</span><span style=\"color: #BABED8\"> buff2.count</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff1</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//计算结果</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">finish</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">buff</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">)</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">buff.total </span><span style=\"color: #89DDFF\">/</span><span style=\"color: #BABED8\"> buff.count</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//缓冲区的编码操作</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">bufferEncoder</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Buff</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">.product</span><span style=\"color: #676E95; font-style: italic\">//输出的编码操作</span></span>\n<span class=\"line\"><span style=\"color: #C792EA\">override</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">outputEncoder</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoder</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">Long</span><span style=\"color: #BABED8\">] </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Encoders</span><span style=\"color: #BABED8\">.scalaLong</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><h3 id=\"数据的加载和保存\"><a href=\"#数据的加载和保存\" class=\"headerlink\" title=\"数据的加载和保存\"></a><strong>数据的加载和保存</strong></h3><h4 id=\"通用的加载和保存方式\"><a href=\"#通用的加载和保存方式\" class=\"headerlink\" title=\"通用的加载和保存方式\"></a>通用的加载和保存方式</h4><p>SparkSQL提供了通用的保存数据和数据加载的方式。这里的通用指的是使用相同的API，根</p>\n<p>据不同的参数读取和保存不同格式的数据，SparkSQL默认读取和保存的文件格式为</p>\n<p>parquet。</p>\n<p>(1)加载数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>spark.read.load 是加载数据的通用方法</p>\n<p>spark . read . &#x2F;&#x2F;tab 键查看方法</p></blockquote>\n<p>如果读取不同格式的数据，可以对不同的数据格式进行设定。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>spark . read . format ( “…” )[. option ( “…” )]. load ( “…” )</p></blockquote>\n<p>1、format(“…”)：指定加载的数据类型，包括”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”。</p>\n<p>2、load(“…”)：在”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”格式下需要传入加载数据的路径。</p>\n<p>3、option(“…”)：在”jdbc”格式下需要传入JDBC相应的参数，url、user、password和dbtable我们前面都适用read API先把文件加载到DataFrame然后再查询，其实我们也可以直接在文件上进行查询：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F; 文件格式 .` 文件路径 `</p>\n<p>&#x2F;&#x2F; 上传 user.json 到 HDFS 上</p>\n<p>&#x2F;&#x2F;hadoop fs -put user.json &#x2F;data</p>\n<p>spark . sql ( “select * from json.`data&#x2F;user.json`“ ). show</p></blockquote>\n<p>(2) 保存数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df.write.save 是保存数据的通用方法</p>\n<p>df . write . &#x2F;&#x2F;tab 键查看方法</p>\n<p>df . write . format ( “json” ). save ( “&#x2F;data&#x2F;output1” )</p></blockquote>\n<p>如果保存不同格式的数据，可以对不同的数据格式进行设定。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df . write . format ( “…” )[. option ( “…” )]. save ( “…” )</p></blockquote>\n<p>1、format(“…”)：指定加载的数据类型，包</p>\n<p>括”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”。</p>\n<p>2、load(“…”)：在”csv”、”jdbc”、”json”、”orc”、”parquet”和”textFile”格式下需要传</p>\n<p>入加载数据的路径。</p>\n<p>3、option(“…”)：在”jdbc”格式下需要传入JDBC相应的参数，url、user、password和</p>\n<p>dbtable保存操作可以使用SaveMode，用来指明如何处理数据，使用mode()方法来设</p>\n<p>置。</p>\n<p><strong>注意：这些SaveMode都是没有加锁的，也不是原子操作。</strong></p>\n<p>SaveMode是一个枚举类，其中的常量包括：</p>\n<p><img src=\"https://i-blog.csdnimg.cn/blog_migrate/ee20e0b010237efd92609b66036cb49d.png\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>df . write . mode ( “append” ). json ( “data&#x2F;output1” )</p>\n<p>df . write . mode ( “overwrite” ). json ( “data&#x2F;output1” )</p>\n<p>df . write . mode ( “ignore” ). json ( “data&#x2F;output1” )</p></blockquote>\n<h4 id=\"parquet\"><a href=\"#parquet\" class=\"headerlink\" title=\"parquet\"></a><strong>parquet</strong></h4><p>SparkSQL的默认数据源为parquet格式。parquet是一种能够有效存储嵌套数据的列式存储</p>\n<p>格式。</p>\n<p>数据源为parquet文件时，SparkSQL可以方便的执行所有的操作，不需要使用format。修改</p>\n<p>配置项<strong>spark.sql.sources.default</strong>,可以修改默认数据源格式。</p>\n<p>(1)加载数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F; 上传文件到 HDFS</p>\n<p>&#x2F;&#x2F;hadoop fs -put users.parquet &#x2F;data</p>\n<p>val df = spark . read . load ( “&#x2F;data&#x2F;users.parquet” )</p>\n<p>df . show</p></blockquote>\n<p>(2)保存数据</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val df = spark . read . json ( “data&#x2F;user.json” )</p>\n<p>df . write . mode ( “append” ). save ( “&#x2F;data&#x2F;output2” )</p></blockquote>\n<h4 id=\"JSON\"><a href=\"#JSON\" class=\"headerlink\" title=\"JSON\"></a><strong>JSON</strong></h4><p>SparkSQL能够自动推测JSON数据集的结构，并将它加载为一个DataSet[ROW]。可以通过</p>\n<p>SparkSession.read.json()去加载JSON文件。</p>\n<p>注意：Spark读取的JSON文件不是传统的JSON文件，每一行都应该是一个JSON串。格式如</p>\n<p>下：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>{<!-- --> “name” : “zhangsan” }</p>\n<p>{<!-- --> “name” : “lisi” , “age” : 21 }</p>\n<p>{<!-- --> “name” : “wangwu” , “age” : 24 },{<!-- --> “name” : “zhaoliu” , “age” : 23 }</p></blockquote>\n<p>(1)导入隐式转换</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>import spark . implicits . _</p></blockquote>\n<p>(2)加载JSON文件</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>val path = “data&#x2F;user.json”</p>\n<p>val userDF = spark . read . json ( path )</p></blockquote>\n<p>(3)创建临时表</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>userDF . createOrReplaceTempView ( “user” )</p></blockquote>\n<p>(4)数据查询</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>spark . sql ( “select * from user” ). show</p></blockquote>\n<h4 id=\"CSV\"><a href=\"#CSV\" class=\"headerlink\" title=\"CSV\"></a><strong>CSV</strong></h4><p>SparkSQL可以配置CSV文件的列表信息，读取CSV文件，CSV文件的第一行设置为数据列 。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F; 上传文件到 HDFS</p>\n<p>&#x2F;&#x2F;hadoop fs -put people.csv &#x2F;data</p>\n<p>val df_csv =</p>\n<p>spark . read . format ( “csv” ). option ( “seq” , “;” ). option ( “inferSchema” , “true” )</p>\n<p>. option ( “header” , “true” ). load ( “&#x2F;data&#x2F;people.csv” )</p></blockquote>\n<h4 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a><strong>MySQL</strong></h4><p>SparkSQL可以通过JDBC从关系型数据库中读取数据的方式创建DataFrame，通过对</p>\n<p>DataFrame一系列的计算后，还可以将数据再写回关系型数据库中。如果使用spark-shell操</p>\n<p>作，可以在启动shell时指定相关的数据库驱动路径或者将相关的数据库驱动放到Spark的类</p>\n<p>路径下 。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>bin &#x2F; spark - shell</p>\n<p>-- jars mysql - connector - java - 5.1 . 27 - bin . jar</p></blockquote>\n<p>我们在IDEA中通过JDBC对Mysql进行操作。</p>\n<p>(1)导入依赖</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&lt;!– <a href=\"https://mvnrepository.com/artifact/mysql/mysql-connector-java\">https://mvnrepository.com/artifact/mysql/mysql-connector-java</a> –&gt;</p>\n<p>&lt;dependency&gt;</p>\n<p>&lt;groupId&gt; mysql &lt;&#x2F;groupId&gt;</p>\n<p>&lt;artifactId&gt; mysql-connector-java &lt;&#x2F;artifactId&gt;</p>\n<p>&lt;version&gt; 5.1.49 &lt;&#x2F;version&gt;</p>\n<p>&lt;&#x2F;dependency&gt;</p></blockquote>\n<p>(2)读取数据</p>\n<div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">expressions</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">Aggregator</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo05_SparkSql_JDBC</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//读取mysql数据</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> df</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> spark.read</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.format(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">jdbc</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">url</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, </span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">jdbc:mysql://master:3306/dtt_data</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//注意mysql5.7用：com.mysql.jdbc.Driver</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">driver</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, </span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">com.mysql.jdbc.Driver</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">user</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, </span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">root</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">password</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, </span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">123456</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">dbtable</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">, </span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">student</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.load()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">// df.show()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">df.write</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.format(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">jdbc</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">url</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">jdbc:mysql://master:3306/dtt_data</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">driver</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">com.mysql.jdbc.Driver</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">user</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">root</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">password</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">123456</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.option(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">dbtable</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">student_1</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.mode(</span><span style=\"color: #FFCB6B\">SaveMode</span><span style=\"color: #BABED8\">.</span><span style=\"color: #FFCB6B\">Append</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.save()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><h4 id=\"Hive\"><a href=\"#Hive\" class=\"headerlink\" title=\"Hive\"></a><strong>Hive</strong></h4><p>ApacheHive是Hadoop上的SQL引擎，SparkSQL编译时可以包含Hive支持，也可以不包含。</p>\n<p>包含Hive支持的SparkSQL可以支持Hive访问、UDF（用户自定义函数）以及 Hive 查询 语言</p>\n<p>(HiveQL&#x2F;HQL)等。需要强调的一点是，如果要在 Spark SQL 中包含 Hive 的库，并不需要事</p>\n<p>先安装 Hive。一般来说，最好还是在编译 Spark SQL 时引入 Hive 支持，这样就可以使用这</p>\n<p>些特性了。如果你下载的是二进制版本的 Spark，它应该已经在编译时添加了 Hive 支持。</p>\n<p>(1)内置的Hive</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F; 内置的 Hive</p>\n<p>&#x2F;&#x2F;spark-shell</p>\n<p>&#x2F;&#x2F; 先删除 spark-local 文件夹中的 metastore_db</p>\n<p>&#x2F;&#x2F; 再执行</p>\n<p>spark . sql ( “show tables” ). show</p>\n<p>&#x2F;&#x2F; 再查看 spark-local 文件夹</p>\n<p>val df = spark . read . json ( “data&#x2F;user.json” )</p>\n<p>df . createOrReplaceTempView ( “user” )</p>\n<p>&#x2F;&#x2F; 可以看到有一张临时表</p>\n<p>spark . sql ( “show tables” ). show</p>\n<p>&#x2F;&#x2F; 创建一个 shujia 表</p>\n<p>spark . sql ( “create table shujia(id int)“ )</p>\n<p>&#x2F;&#x2F; 加载数据</p>\n<p>&#x2F;&#x2F; 加载数据之前需要在 data 文件夹下创建一个 id.txt 文件</p>\n<p>spark . sql ( “load data local inpath’data&#x2F;id.txt’ into table shujia” )</p>\n<p>&#x2F;&#x2F; 查询</p>\n<p>spark . sql ( “select * from shujia” ). show</p></blockquote>\n<p>在实际开发中，几乎没有任何人回使用内置的Hive。</p>\n<p>(2)外部的Hive</p>\n<p>如果想连接外部已经部署好的Hive，需要通过以下几个步骤：</p>\n<p>(1)Spark要接管Hive需要把hive-site.xml文件拷贝到conf&#x2F;目录下；</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>[root@master conf] # cp hive-site.xml &#x2F;usr&#x2F;local&#x2F;soft&#x2F;spark-local&#x2F;conf&#x2F;</p></blockquote>\n<p>(2)把mysql的驱动copy到jars&#x2F;目录下；</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>[root@master packages] # cp mysql-connector-java-5.1.49.jar &#x2F;usr&#x2F;local&#x2F;soft&#x2F;spark-local&#x2F;jars&#x2F;</p></blockquote>\n<p>(3)如果访问不到hdfs，则需要把core-site.xml和hdfs-site.xml拷贝到conf&#x2F;目录下</p>\n<p>(4)重启spark-shell</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>bin &#x2F; spark - shell</p></blockquote>\n<p>(5)代码操作Hive</p>\n<p><strong>添加依赖：</strong></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&lt;!– <a href=\"https://mvnrepository.com/artifact/org.apache.spark/spark-hive\">https://mvnrepository.com/artifact/org.apache.spark/spark-hive</a> –&gt;</p>\n<p>&lt;dependency&gt;</p>\n<p>&lt;groupId&gt; org.apache.spark &lt;&#x2F;groupId&gt;</p>\n<p>&lt;artifactId&gt; spark-hive_2.12 &lt;&#x2F;artifactId&gt;</p>\n<p>&lt;version&gt; 2.4.5 &lt;&#x2F;version&gt;</p>\n<p>&lt;&#x2F;dependency&gt;</p>\n<p>&lt;!– <a href=\"https://mvnrepository.com/artifact/org.apache.hive/hive-exec\">https://mvnrepository.com/artifact/org.apache.hive/hive-exec</a> –&gt;</p>\n<p>&lt;dependency&gt;</p>\n<p>&lt;groupId&gt; org.apache.hive &lt;&#x2F;groupId&gt;</p>\n<p>&lt;artifactId&gt; hive-exec &lt;&#x2F;artifactId&gt;</p>\n<p>&lt;version&gt; 1.2.1 &lt;&#x2F;version&gt;</p>\n<p>&lt;&#x2F;dependency&gt;</p></blockquote>\n<p><strong>编写代码：</strong></p>\n<div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">core</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">_</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Demo06_SparkSql_Hive</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().enableHiveSupport().config(sparkConf).getOrCreat</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">e()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//使用SparkSQL连接外置的Hive</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//1、拷贝hive-site.xml文件到classpath下</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//2、启用hive到支持.enableHiveSupport()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//3、增加对应到依赖关系（包含Mysql驱动）</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 执行逻辑操作</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">show tables</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">).show()</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 关闭环境</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><p>以下是某一种报错的解决办法</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>&#x2F;&#x2F;Error while instantiating</p>\n<p>‘org.apache.spark.sql.hive.HiveSessionState’:</p>\n<p>java.lang.RuntimeException: The root scratch dir: &#x2F;tmp&#x2F;hive on HDFS</p>\n<p>should be writable. Current permissions are: ———</p>\n<p>% HADOOP_HOME % \\bin\\winutils . exe ls E : \\tmp\\hive</p>\n<p>% HADOOP_HOME % \\bin\\winutils . exe chmod 777 E : \\tmp\\hive</p>\n<p>% HADOOP_HOME % \\bin\\winutils . exe ls E : \\tmp\\hive</p>\n<p>&#x2F;&#x2F; 遇到的错误：修改 hive 元数据库的字符集编码</p>\n<p>mysql &gt; alter database hive character set latin1 ;</p></blockquote>\n<h2 id=\"SparkSQL代码样例\"><a href=\"#SparkSQL代码样例\" class=\"headerlink\" title=\"SparkSQL代码样例\"></a>SparkSQL代码样例</h2><p> </p>\n<div class=\"language-scala\"><button title=\"Copy code\" class=\"copy\"></button><span class=\"lang\">scala</span><pre class=\"shiki material-theme-palenight\" style=\"background-color: #1a1a1a\" tabindex=\"0\"><code><span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//使用spark加载数据</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">package</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">com</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">shujia</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">test</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">SparkConf</span></span>\n<span class=\"line\"><span style=\"color: #F78C6C\">import</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">org</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">apache</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">spark</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #FFCB6B\">sql</span><span style=\"color: #89DDFF\">.</span><span style=\"color: #BABED8\">&#123;</span><span style=\"color: #FFCB6B\">DataFrame</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SaveMode</span><span style=\"color: #BABED8\">, </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">object</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">DemoSpark_hive</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">def</span><span style=\"color: #BABED8\"> </span><span style=\"color: #82AAFF\">main</span><span style=\"color: #BABED8\">(</span><span style=\"color: #BABED8; font-style: italic\">args</span><span style=\"color: #BABED8\">: </span><span style=\"color: #FFCB6B\">Array</span><span style=\"color: #BABED8\">[</span><span style=\"color: #FFCB6B\">String</span><span style=\"color: #BABED8\">])</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">Unit</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">&#123;</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">System</span><span style=\"color: #BABED8\">.setProperty(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">HADOOP_USER_NAME</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">,</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">root</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #676E95; font-style: italic\">//TODO 创建SparkSQL的运行环境</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> sparkConf</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">new</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkConf</span><span style=\"color: #BABED8\">()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setMaster(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">local[*]</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.setAppName(</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #C3E88D\">SparkSql</span><span style=\"color: #89DDFF\">&quot;</span><span style=\"color: #BABED8\">)</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">val</span><span style=\"color: #BABED8\"> spark</span><span style=\"color: #89DDFF\">:</span><span style=\"color: #BABED8\"> </span><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\"> </span><span style=\"color: #89DDFF\">=</span></span>\n<span class=\"line\"><span style=\"color: #FFCB6B\">SparkSession</span><span style=\"color: #BABED8\">.builder().enableHiveSupport().config(sparkConf).getOrCreate()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|create table user_log_action(</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `date` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `user_id` bigint,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `session_id` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `page_id` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `action_time` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `search_keyword` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `click_category_id` bigint,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `click_product_id` bigint,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `order_category_ids` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `order_product_ids` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `pay_category_ids` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `pay_product_ids` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `city_id` bigint</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|)</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|row format delimited fields terminated by &#39;\\t&#39;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|load data local inpath &#39;data/user_log_action.txt&#39; into table</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">user_log_action</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|create table product_info(</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `product_id` bigint,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `product_name` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `extend_info` string</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|)</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|row format delimited fields terminated by &#39;\\t&#39;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|load data local inpath &#39;data/product_info.txt&#39; into table</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">product_info</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|create table city_info(</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `city_id` bigint,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `city_name` string,</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">| `area` string</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|)</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|row format delimited fields terminated by &#39;\\t&#39;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|load data local inpath &#39;data/city_info.txt&#39; into table city_info</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.sql(</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|select * from product_info</span></span>\n<span class=\"line\"><span style=\"color: #C3E88D\">|</span><span style=\"color: #89DDFF\">&quot;&quot;&quot;</span><span style=\"color: #BABED8\">.stripMargin)</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">.show()</span></span>\n<span class=\"line\"><span style=\"color: #BABED8\">spark.close()</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span>\n<span class=\"line\"><span style=\"color: #89DDFF\">&#125;</span></span></code></pre></div><p>Article link： <a href=\"https://tqgoblin.site/post/csdn/SparkSQL%E8%AF%A6%E8%A7%A3/\">https://tqgoblin.site/post/csdn/SparkSQL详解/</a> <div align=left> Author：<a href=\"https://www.tqgoblin.site\"> Stephen </a> </div></p>\n","text":" 目录 SparkSQL概述 什么是Spark SQL Spark SQL特点 什么是DataFrame RDD与DataFrame区别： 什么是DataSet...","permalink":"/post/csdn/SparkSQL详解","photos":[],"count_time":{"symbolsCount":"27k","symbolsTime":"24 mins."},"categories":[{"name":"大数据","slug":"大数据","count":7,"path":"api/categories/大数据.json"}],"tags":[{"name":"spark","slug":"spark","count":3,"path":"api/tags/spark.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SparkSQL-%E6%A6%82%E8%BF%B0\"><span class=\"toc-text\">SparkSQL****概述</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF-Spark-SQL\"><span class=\"toc-text\">什么是****Spark SQL</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Spark-SQL-%E7%89%B9%E7%82%B9\"><span class=\"toc-text\">Spark SQL****特点</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF-DataFrame\"><span class=\"toc-text\">什么是****DataFrame</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#RDD%E4%B8%8EDataFrame-%E5%8C%BA%E5%88%AB%EF%BC%9A\"><span class=\"toc-text\">RDD与DataFrame****区别：</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BB%80%E4%B9%88%E6%98%AF-DataSet\"><span class=\"toc-text\">什么是****DataSet</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SparkSQL-%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">SparkSQL****编程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%96%B0%E7%9A%84%E8%B5%B7%E5%A7%8B%E7%82%B9\"><span class=\"toc-text\">新的起始点</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#DataFrame\"><span class=\"toc-text\">DataFrame</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%9B%E5%BB%BA\"><span class=\"toc-text\">创建</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#SQL-%E8%AF%AD%E6%B3%95\"><span class=\"toc-text\">SQL****语法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#DSL-%E8%AF%AD%E6%B3%95\"><span class=\"toc-text\">DSL****语法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#RDD%E8%BD%AC%E6%8D%A2%E4%B8%BADataFrame-DataFrame%E8%BD%AC%E6%8D%A2%E4%B8%BARDD\"><span class=\"toc-text\">RDD转换为DataFrame&amp;DataFrame转换为RDD</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#DataSet\"><span class=\"toc-text\">DataSet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%9B%E5%BB%BA-DataSet\"><span class=\"toc-text\">创建****DataSet</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#DataFrame%E8%BD%ACDataSet-DataSet%E8%BD%ACDataFrame\"><span class=\"toc-text\">DataFrame转DataSet&amp;DataSet转DataFrame</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#RDD%E8%BD%ACDataSet-DataSet%E8%BD%ACRDD\"><span class=\"toc-text\">RDD转DataSet&amp;DataSet转RDD</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#RDD%E3%80%81DataFrame%E3%80%81DataSet-%E4%B8%89%E8%80%85%E7%9A%84%E5%85%B3%E7%B3%BB\"><span class=\"toc-text\">RDD、DataFrame、DataSet****三者的关系</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC%E5%8C%BA%E5%88%AB\"><span class=\"toc-text\">版本区别</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%B8%89%E8%80%85%E7%9A%84%E5%85%B1%E6%80%A7\"><span class=\"toc-text\">三者的共性</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB\"><span class=\"toc-text\">三者的区别</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#IDEA%E5%88%9B%E5%BB%BASparkSQL%E7%A8%8B%E5%BA%8F\"><span class=\"toc-text\">IDEA创建SparkSQL程序</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">用户自定义函数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#1%E3%80%81%E5%88%9B%E5%BB%BADataFrame\"><span class=\"toc-text\">1、创建DataFrame</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#2%E3%80%81%E7%94%A8%E6%88%B7%E8%87%AA%E5%AE%9A%E4%B9%89%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0-%E5%BC%B1%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">2、用户自定义聚合函数(弱类型)</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98\"><span class=\"toc-text\">数据的加载和保存</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%80%9A%E7%94%A8%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">通用的加载和保存方式</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#parquet\"><span class=\"toc-text\">parquet</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#JSON\"><span class=\"toc-text\">JSON</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#CSV\"><span class=\"toc-text\">CSV</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#MySQL\"><span class=\"toc-text\">MySQL</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Hive\"><span class=\"toc-text\">Hive</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#SparkSQL%E4%BB%A3%E7%A0%81%E6%A0%B7%E4%BE%8B\"><span class=\"toc-text\">SparkSQL代码样例</span></a></li></ol>","author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"SparkStreaming","uid":"050e941d853c6afbf79df52c3d4149bb","slug":"csdn/SparkStreaming","date":"2023-02-06T09:24:47.000Z","updated":"2025-02-17T01:58:21.583Z","comments":true,"path":"api/articles/csdn/SparkStreaming.json","keywords":"Stephen web3","cover":[],"text":" 目录 SparkStreaming概述 SparkStreaming是什么 SparkStreaming特点 Spark Streaming架构 Dstrea...","permalink":"/post/csdn/SparkStreaming","photos":[],"count_time":{"symbolsCount":"15k","symbolsTime":"14 mins."},"categories":[{"name":"大数据","slug":"大数据","count":7,"path":"api/categories/大数据.json"}],"tags":[{"name":"spark","slug":"spark","count":3,"path":"api/tags/spark.json"}],"author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},"next_post":{"title":"Spark详解","uid":"76e2b6bc5d139da0618aa8a268fb05fa","slug":"csdn/Spark详解","date":"2023-02-06T07:47:39.000Z","updated":"2025-02-17T01:58:21.585Z","comments":true,"path":"api/articles/csdn/Spark详解.json","keywords":"Stephen web3","cover":[],"text":" 目录 第1章：Spark概述 1.1 Spark是什么 1.2 Spark and Hadoop 1.3 Spark on Hadoop 1.4 Spark核...","permalink":"/post/csdn/Spark详解","photos":[],"count_time":{"symbolsCount":"52k","symbolsTime":"48 mins."},"categories":[{"name":"大数据","slug":"大数据","count":7,"path":"api/categories/大数据.json"}],"tags":[{"name":"spark","slug":"spark","count":3,"path":"api/tags/spark.json"}],"author":{"name":"Stephen","slug":"blog-author","avatar":"../img/logo.png","link":"/","description":"Love and Share","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}